{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Prashant\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This notebook expects the data to be in the \"CL class project materials\" folder in the root folder\n",
    "Install the pandas, numpy, nltk, empath libraries atleast before running this\n",
    "'''\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.en import English\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import  KFold, StratifiedKFold, cross_val_score, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import sklearn.metrics as metrics\n",
    "from collections import Counter\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from empath import Empath\n",
    "from scipy import sparse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "'''\n",
    "Helper functions\n",
    "'''\n",
    "def normalize_tokens(tokenlist):\n",
    "    normalized_tokens = [token.lower().replace('_','+') for token in tokenlist   \n",
    "                             if re.search('[^\\s]', token) is not None            \n",
    "                             and not token.startswith(\"@\")                       \n",
    "                        ]\n",
    "    return normalized_tokens        \n",
    "\n",
    "def ngrams(tokens, n):\n",
    "    return [tokens[i:i+n] for i in range(len(tokens)-n+1)]\n",
    "\n",
    "def filter_punctuation_bigrams(ngrams):\n",
    "    punct = string.punctuation\n",
    "    return [ngram   for ngram in ngrams   if ngram[0] not in punct and ngram[1] not in punct]\n",
    "\n",
    "def filter_stopword_bigrams(ngrams, stopwords):\n",
    "    result = [ngram   for ngram in ngrams   if ngram[0] not in stopwords and ngram[1] not in stopwords]\n",
    "    return result\n",
    "\n",
    "def whitespace_tokenizer(line):\n",
    "    return line.split() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Helper functions for convert text lines to features\n",
    "'''\n",
    "\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')    \n",
    "\n",
    "\n",
    "def convert_lines_to_feature_strings(line, stopwords, remove_stopword_bigrams=True):\n",
    "    line = line.translate(str.maketrans('', '', string.punctuation))\n",
    "    spacy_analysis = nlp(line)\n",
    "    spacy_tokens = [token.orth_ for token in spacy_analysis]\n",
    "    normalized_tokens = normalize_tokens(spacy_tokens)\n",
    "\n",
    "    unigrams          = [token   for token in normalized_tokens\n",
    "                             if token not in stopwords and token not in string.punctuation]\n",
    "\n",
    "    bigrams = []\n",
    "    bigram_tokens     = [\"_\".join(bigram) for bigram in bigrams]\n",
    "    bigrams           = ngrams(normalized_tokens, 2) \n",
    "    bigrams           = filter_punctuation_bigrams(bigrams)\n",
    "    if remove_stopword_bigrams:\n",
    "        bigrams = filter_stopword_bigrams(bigrams, stopwords)\n",
    "    bigram_tokens = [\"_\".join(bigram) for bigram in bigrams]\n",
    "    feature_string = \" \".join ([\" \".join(unigrams),\" \".join(bigram_tokens)])\n",
    "    return feature_string\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def convert_text_into_features(X, stopwords_arg, analyzefn=\"word\", range=(1,2), vocabulary=None):\n",
    "    training_vectorizer = CountVectorizer(stop_words=stopwords_arg,\n",
    "                                          analyzer=analyzefn,\n",
    "                                          lowercase=True,\n",
    "                                          ngram_range=range,\n",
    "                                          vocabulary=vocabulary)\n",
    "    X_features = training_vectorizer.fit_transform(X)\n",
    "    return X_features, training_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon = Empath()\n",
    "'''\n",
    "Convert text to emotion score features\n",
    "'''\n",
    "def line_to_emotion_features(lines, lexicon, categories=[\"negative_emotion\", \"positive_emotion\",\"pain\",\"poor\",\"disappointment\"], normalize=False):\n",
    "    scores = []\n",
    "    for line in lines:\n",
    "        score_dict = lexicon.analyze(line, categories=categories, normalize=normalize)\n",
    "        if score_dict:\n",
    "            score = [score_dict[cat] for cat in categories]\n",
    "        else:\n",
    "            score = [0 for cat in categories]\n",
    "        scores.append(score)\n",
    "    return sparse.csr_matrix(np.array(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0.],\n",
       "       [1., 0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!pip3.7 install empath\n",
    "'''\n",
    "Stub block\n",
    "'''\n",
    "text='the cool cat is in the box'\n",
    "\n",
    "print(text)\n",
    "text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "print(text)\n",
    "spacy_analysis = nlp(text)\n",
    "spacy_tokens = [token.orth_ for token in spacy_analysis]\n",
    "spacy_nouns = [x for x in spacy_analysis.noun_chunks]\n",
    "print(spacy_nouns)\n",
    "normalized_tokens = normalize_tokens(spacy_tokens)\n",
    "\n",
    "\n",
    "lexicon = Empath()\n",
    "\n",
    "lines=['what the fuck','i will kill myself','i love cocaine']\n",
    "\n",
    "#lines.apply(line_to_emotion_features, args=(lexicon, [\"negative_emotion\", \"positive_emotion\"]))\n",
    "\n",
    "line_to_emotion_features(lines, lexicon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40130</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19368</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20841</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8720</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32730</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id label\n",
       "0    40130     a\n",
       "1    19368     a\n",
       "2    20841     a\n",
       "3     8720     a\n",
       "4    32730     a"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df = pd.read_csv(\"CL class project materials/umd_reddit_suicidewatch_dataset_v2/crowd/train/crowd_train.csv\")\n",
    "\n",
    "labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>post_title</th>\n",
       "      <th>post_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wfimt</td>\n",
       "      <td>22002</td>\n",
       "      <td>1342075703</td>\n",
       "      <td>GetMotivated</td>\n",
       "      <td>[real] motivation</td>\n",
       "      <td>This is my first post on reddit. Some time ago...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1bsqv3</td>\n",
       "      <td>22002</td>\n",
       "      <td>1365261010</td>\n",
       "      <td>leagueoflegends</td>\n",
       "      <td>simple question about transfering acc to anoth...</td>\n",
       "      <td>Hi.. What will happen with my ranked rating? I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1buqml</td>\n",
       "      <td>22002</td>\n",
       "      <td>1365345637</td>\n",
       "      <td>seduction</td>\n",
       "      <td>_PERSON_ up ever (crosspost from r/GetMotivated</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1dr0xf</td>\n",
       "      <td>22002</td>\n",
       "      <td>1367787358</td>\n",
       "      <td>leagueoflegends</td>\n",
       "      <td>simple question: Did you get unnbaned?</td>\n",
       "      <td>Hi. Simple question. Did you get unban from a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1e0noi</td>\n",
       "      <td>22002</td>\n",
       "      <td>1368125785</td>\n",
       "      <td>leagueoflegends</td>\n",
       "      <td>I can't win. Why... and it's noy my fault.</td>\n",
       "      <td>Hi... Am playing at Eu west... am diamond 5 ri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  post_id  user_id   timestamp        subreddit  \\\n",
       "0   wfimt    22002  1342075703     GetMotivated   \n",
       "1  1bsqv3    22002  1365261010  leagueoflegends   \n",
       "2  1buqml    22002  1365345637        seduction   \n",
       "3  1dr0xf    22002  1367787358  leagueoflegends   \n",
       "4  1e0noi    22002  1368125785  leagueoflegends   \n",
       "\n",
       "                                          post_title  \\\n",
       "0                                  [real] motivation   \n",
       "1  simple question about transfering acc to anoth...   \n",
       "2    _PERSON_ up ever (crosspost from r/GetMotivated   \n",
       "3             simple question: Did you get unnbaned?   \n",
       "4         I can't win. Why... and it's noy my fault.   \n",
       "\n",
       "                                           post_body  \n",
       "0  This is my first post on reddit. Some time ago...  \n",
       "1  Hi.. What will happen with my ranked rating? I...  \n",
       "2                                                NaN  \n",
       "3  Hi. Simple question. Did you get unban from a ...  \n",
       "4  Hi... Am playing at Eu west... am diamond 5 ri...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_df = pd.read_csv(\"CL class project materials/umd_reddit_suicidewatch_dataset_v2/crowd/train/shared_task_posts.csv\")\n",
    "\n",
    "posts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.merge(posts_df, labels_df, on=[\"user_id\"])\n",
    "train_data = train_data.drop([\"post_id\", \"timestamp\", \"subreddit\"], axis=1)\n",
    "train_data = train_data.dropna()\n",
    "train_data[\"binary_label\"] = train_data.label.map({\"a\" : 0, \"b\" : 0, \"c\" : 0, \"d\" : 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id         16601\n",
       "post_title      16601\n",
       "post_body       16601\n",
       "label           16601\n",
       "binary_label    16601\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Add a \"features\" column which is unigram and bigram features\n",
    "'''\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "train_data['features'] = train_data['post_body'].apply(convert_lines_to_feature_strings, args=(stop_words, True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "More in negative\n",
      "\n",
      "More in postive\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "LLR implementation to include the N best uni/bigram features\n",
    "'''\n",
    "\n",
    "pos_counter = Counter()\n",
    "for post in train_data['features'][train_data['binary_label'] == 1]:\n",
    "    for x in post.split(' '):\n",
    "        pos_counter[x] += 1\n",
    "        \n",
    "neg_counter = Counter()\n",
    "for post in train_data['features'][train_data['binary_label'] == 0]:\n",
    "    for x in post.split(' '):\n",
    "        neg_counter[x] += 1\n",
    "\n",
    "import llr\n",
    "\n",
    "\n",
    "diff = llr.llr_compare(pos_counter, neg_counter)\n",
    "ranked = sorted(diff.items(), key=lambda x: x[1])\n",
    "\n",
    "N = 5000\n",
    "\n",
    "vocab = []\n",
    "\n",
    "print(\"\\nMore in negative\")\n",
    "for k,v in ranked[:N]:\n",
    "    vocab.append(k)\n",
    "\n",
    "print(\"\\nMore in postive\")\n",
    "for k,v in ranked[-N:]:\n",
    "    vocab.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before resample counts: Counter({0: 9495, 1: 7106})\n",
      "After resample counts: Counter({0: 9495, 1: 9495})\n",
      "Classifying test data using LR\n",
      "Accuracy  = 0.7427593470247499\n",
      "Precision for label 0 = 0.6811671087533157\n",
      "Recall    for label 0 = 0.7734939759036145\n",
      "Precision for label 1 = 0.803450078410873\n",
      "Recall    for label 1 = 0.7188961646398503\n"
     ]
    }
   ],
   "source": [
    "X = train_data['features']\n",
    "y = train_data['binary_label']\n",
    "\n",
    "\n",
    "'''\n",
    "Vectorize data\n",
    "'''\n",
    "\n",
    "\n",
    "X_vec, training_vectorizer = convert_text_into_features(X, stopwords_arg= stop_words, analyzefn=whitespace_tokenizer, range=(1,2), vocabulary=vocab)\n",
    "X_emo = line_to_emotion_features(X, lexicon=lexicon, categories=[\"negative_emotion\", \"positive_emotion\"], normalize=False)\n",
    "X_ft = sparse.hstack((X_vec, X_emo))\n",
    "#X_ft = X_vec\n",
    "\n",
    "\n",
    "'''\n",
    "Resampling using SMOTE for imbalanced dataset\n",
    "'''\n",
    "X_resampled, y_resampled = SMOTE().fit_resample(X_ft, y)\n",
    "print(\"Before resample counts: {}\".format(Counter(y)))\n",
    "print(\"After resample counts: {}\".format(Counter(y_resampled)))\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "lr_classifier = LogisticRegression(solver='liblinear')\n",
    "svc_classifier = SVC(kernel='linear')\n",
    "\n",
    "lr_classifier.fit(X_train, y_train)\n",
    "\n",
    "print(\"Classifying test data using LR\")\n",
    "predicted_labels = lr_classifier.predict(X_test)\n",
    "print('Accuracy  = {}'.format(metrics.accuracy_score(predicted_labels,  y_test)))\n",
    "for label in [0, 1]:\n",
    "    print('Precision for label {} = {}'.format(label, metrics.precision_score(predicted_labels, y_test, pos_label=label)))\n",
    "    print('Recall    for label {} = {}'.format(label, metrics.recall_score(predicted_labels,    y_test, pos_label=label)))\n",
    "    \n",
    "#metrics.plot_confusion_matrix(lr_classifier, X_train.toarray(), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy scores = [0.7153669  0.72030273 0.72119816 0.71757735 0.72251481], mean = 0.7193919901495611, stdev = 0.0025821690999201755\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "K-Folds\n",
    "'''\n",
    "kfold = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "accuracy_scores = cross_val_score(lr_classifier, X_train, y_train, scoring='accuracy', cv=kfold, n_jobs=-1)\n",
    "print(\"accuracy scores = {}, mean = {}, stdev = {}\".format(\n",
    "        accuracy_scores, np.mean(accuracy_scores), np.std(accuracy_scores)), flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying test data using Random Forest\n",
      "Accuracy  = 0.6187467087941022\n",
      "Precision for label 0 = 0.5262599469496021\n",
      "Recall    for label 0 = 0.6412411118293472\n",
      "Precision for label 1 = 0.7098797699947726\n",
      "Recall    for label 1 = 0.6032874278098623\n",
      "accuracy scores = [0.61204344 0.64100033 0.62277814 0.62903226 0.62574062], mean = 0.6261189569608693, stdev = 0.009374081734716162\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Random Forest Classifier\n",
    "'''\n",
    "rf_classifier = RandomForestClassifier(max_depth=4, random_state=0)\n",
    "\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "print(\"Classifying test data using Random Forest\")\n",
    "predicted_labels = rf_classifier.predict(X_test)\n",
    "print('Accuracy  = {}'.format(metrics.accuracy_score(predicted_labels,  y_test)))\n",
    "for label in [0, 1]:\n",
    "    print('Precision for label {} = {}'.format(label, metrics.precision_score(predicted_labels, y_test, pos_label=label)))\n",
    "    print('Recall    for label {} = {}'.format(label, metrics.recall_score(predicted_labels,    y_test, pos_label=label)))\n",
    "    \n",
    "rf_classifier = RandomForestClassifier(max_depth=4, random_state=0)\n",
    "\n",
    "accuracy_scores = cross_val_score(rf_classifier, X_train, y_train, scoring='accuracy', cv=kfold, n_jobs=-1)\n",
    "print(\"accuracy scores = {}, mean = {}, stdev = {}\".format(\n",
    "        accuracy_scores, np.mean(accuracy_scores), np.std(accuracy_scores)), flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying test data using Random Forest\n",
      "Accuracy  = 0.7630331753554502\n",
      "Precision for label 0 = 0.5522546419098143\n",
      "Recall    for label 0 = 0.9489516864175023\n",
      "Precision for label 1 = 0.970726607422896\n",
      "Recall    for label 1 = 0.6875231395779341\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x28e60674888>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "Naive Bayes\n",
    "'''\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nb_classifier = GaussianNB()\n",
    "nb_classifier.fit(X_train.toarray(), y_train)\n",
    "\n",
    "print(\"Classifying test data using Random Forest\")\n",
    "predicted_labels = nb_classifier.predict(X_test.toarray())\n",
    "print('Accuracy  = {}'.format(metrics.accuracy_score(predicted_labels,  y_test)))\n",
    "for label in [0, 1]:\n",
    "    print('Precision for label {} = {}'.format(label, metrics.precision_score(predicted_labels, y_test, pos_label=label)))\n",
    "    print('Recall    for label {} = {}'.format(label, metrics.recall_score(predicted_labels,    y_test, pos_label=label)))\n",
    "\n",
    "    '''\n",
    "nb_classifier = GaussianNB()\n",
    "\n",
    "accuracy_scores = cross_val_score(nb_classifier, X_train.toarray(), y_train, scoring='accuracy', cv=kfold, n_jobs=-1)\n",
    "print(\"accuracy scores = {}, mean = {}, stdev = {}\".format(\n",
    "        accuracy_scores, np.mean(accuracy_scores), np.std(accuracy_scores)), flush=True)\n",
    "        '''\n",
    "    \n",
    "metrics.plot_confusion_matrix(nb_classifier, X_train.toarray(), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying test data using SVC\n",
      "Accuracy  = 0.6648235913638757\n",
      "Precision for label 0 = 0.47586206896551725\n",
      "Recall    for label 0 = 0.7588832487309645\n",
      "Precision for label 1 = 0.851019341348667\n",
      "Recall    for label 1 = 0.6223241590214067\n",
      "accuracy scores = [0.65712405 0.65876933 0.64845293 0.64812377 0.65371955], mean = 0.6532379267027003, stdev = 0.0043584684051423935\n"
     ]
    }
   ],
   "source": [
    "svc_classifier.fit(X_train, y_train)\n",
    "\n",
    "print(\"Classifying test data using SVC\")\n",
    "predicted_labels = svc_classifier.predict(X_test)\n",
    "print('Accuracy  = {}'.format(metrics.accuracy_score(predicted_labels,  y_test)))\n",
    "for label in [0, 1]:\n",
    "    print('Precision for label {} = {}'.format(label, metrics.precision_score(predicted_labels, y_test, pos_label=label)))\n",
    "    print('Recall    for label {} = {}'.format(label, metrics.recall_score(predicted_labels,    y_test, pos_label=label)))\n",
    "    \n",
    "svc_classifier = SVC(kernel='linear')\n",
    "\n",
    "accuracy_scores = cross_val_score(svc_classifier, X_train, y_train, scoring='accuracy', cv=kfold, n_jobs=-1)\n",
    "print(\"accuracy scores = {}, mean = {}, stdev = {}\".format(\n",
    "        accuracy_scores, np.mean(accuracy_scores), np.std(accuracy_scores)), flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
